def QsAnswer(questionId):
    # 每次我们取10条回答
    limit = 10
    # 获取答案时的偏移量
    offset = 0
    # 开始时假设当前有这么多的回答，得到请求后我再解析
    total = 2 * limit;
    # 我们当前已记录的回答数量
    record_num = 0
    # 定义问题的标题，为了避免获取失败，我们在此先赋值
    title = questionId
    # 存储所有的答案信息
    answer_info = []

    print('Fetch info start...')
    #url = 'https://www.zhihu.com/question/369097579'+str(topicId)+'/organize'
    #html= session.get(url, headers=headers,proxies=proxyip,timeout=10)
    #soup=BeautifulSoup(html.text)
    while record_num < total:
            # 开始获取数据
            # 我们获取数据的URL格式是什么样呢？
            # https://www.zhihu.com/api/v4/questions/39162814/answers?
            #https://www.zhihu.com/question/369097579/answer/1014809028
            #https://www.zhihu.com/question/369097579/answer/1015505656
            # sort_by=default&include=data[*].is_normal,content&limit=5&offset=0
            
            url = 'https://www.zhihu.com/questions/' + questionId + '/answers/'+ str(record_num)
            response= session.get(url, headers=headers,proxies=proxyip,timeout=10)

            # 返回的信息为json类型
            response = json.loads(response.content)

            # 其中的paging实体包含了前一页&下一页的URL，可据此进行循环遍历获取回答的内容
            # 我们先来看下总共有多少回答
            total = response['paging']['totals']

            # 本次请求返回的实体信息数组
            datas = response['data']

            # 遍历信息并记录
            if datas is not None:

                if total <= 0:
                    break

                for data in datas:
                    dr = re.compile(r'<[^>]+>', re.S)
                    content = dr.sub('', data['content'])
                    answer = data['author']['name'] + ' ' + str(data['voteup_count']) + ' 人点赞' + '\n'
                    answer = answer + 'Answer:' + content + '\n'
                    answer_info.append('\n')
                    answer_info.append(answer)
                    answer_info.append('\n')
                    answer_info.append('------------------------------')
                    answer_info.append('\n')
                    # 获取问题的title
                    title = data['question']['title']


                # 请求的向后偏移量
                offset += len(datas)
                record_num += len(datas)

                # 如果获取的数组size小于limit,循环结束
                if len(datas) < limit:
                    break;
    print('Fetch info end...')
    answer_info.insert(0, title + '\n')
    questionId.write2File(title + '.txt', answer_info)

    def write2File(filePath, answer_info):
        print('Write info to file:Start...')
        # 将文件内容写到文件中
        filePath="C:/Users/Administrator/Desktop/知乎爬虫"
        with open(filePath, 'a', encoding='utf-8') as f:
            f.writelines('\n\n')
            for text in answer_info:
                f.writelines(text)
            f.writelines('\n\n')
            print('Write info to file:end...')
